{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ³  Common recipes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section introduces common recipes you might need while using `PyTreeClass` to train/build models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Add a leaf to the instance after instantiation.\n",
    "\n",
    "The following recipe, adds a method `add_leaf` that sets a leaf value and name. however, since this method mutate the internal state of the instance `.at['add_leaf']` is used to apply the method functionally and return method call value and a **new** instance ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tree(a=1.0, b=2.0, c=3.0, d=4.0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytreeclass as pytc\n",
    "\n",
    "\n",
    "@pytc.autoinit\n",
    "class Tree(pytc.TreeClass):\n",
    "    a: float = 1.0\n",
    "    b: float = 2.0\n",
    "    c: float = 3.0\n",
    "\n",
    "    def add_leaf(self, name: str, value):\n",
    "        setattr(self, name, value)\n",
    "\n",
    "\n",
    "tree = Tree()\n",
    "# Tree(a=1.0, b=2.0, c=3.0)\n",
    "\n",
    "_, tree_with_d = tree.at[\"add_leaf\"](\"d\", 4.0)\n",
    "\n",
    "tree_with_d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Customize optimizers-leaf updates using `PyTreeClass` mask + `Optax`.\n",
    "The following recipe, `optax.masked` is used to apply certain optmizers to certain leaves using masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "import pytreeclass as pytc\n",
    "import jax\n",
    "\n",
    "\n",
    "@pytc.autoinit\n",
    "class Tree(pytc.TreeClass):\n",
    "    a: float = 1.0\n",
    "    b: float = 2.0\n",
    "    c: float = 3.0\n",
    "\n",
    "\n",
    "tree = Tree()\n",
    "\n",
    "false_mask = tree.at[...].set(False)\n",
    "\n",
    "a_mask = false_mask.at[\"a\"].set(True)\n",
    "b_mask = false_mask.at[\"b\"].set(True)\n",
    "c_mask = false_mask.at[\"c\"].set(True)\n",
    "\n",
    "optim = optax.chain(\n",
    "    # update `a` with sgd of learning rate 1\n",
    "    optax.masked(optax.sgd(learning_rate=1), a_mask),\n",
    "    # update `b` with sgd of learning rate -1\n",
    "    optax.masked(optax.sgd(learning_rate=-1), b_mask),\n",
    "    # update `c` with sgd of learning rate 0\n",
    "    optax.masked(optax.sgd(learning_rate=0), c_mask),\n",
    ")\n",
    "\n",
    "\n",
    "# freeze non-differentiable parameters\n",
    "# in this case all parameters are differentiable\n",
    "# but we do it incase we add a non-differentiable parameter later\n",
    "tree = tree.at[jax.tree_map(pytc.is_nondiff, tree)].apply(pytc.freeze)\n",
    "\n",
    "optim_state = optim.init(tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Use `numpy` functions on `TreeClass` instance.\n",
    "`jax.numpy` functions can be applied to `TreeClass` instance using a function transformation `bcmap` around the `numpy` function and enabling the feature through `@leafwise`. `@leafwise` additionally enable math operation per-leaf, for example `tree`+1 will add 1 to all leaves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree(a=0, b=(0.0, 103.0), c=[104. 105. 106.])\n",
      "Tree(a=1, b=(102.0, 103.0), c=[104. 105. 106.])\n",
      "Tree(a=1, b=(102.0, 103.0), c=[104. 105. 106.])\n"
     ]
    }
   ],
   "source": [
    "import pytreeclass as pytc\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "@pytc.leafwise\n",
    "@pytc.autoinit\n",
    "class Tree(pytc.TreeClass):\n",
    "    a: int = 1\n",
    "    b: tuple[float] = (2.0, 3.0)\n",
    "    c: jax.Array = jnp.array([4.0, 5.0, 6.0])\n",
    "\n",
    "\n",
    "tree = Tree()\n",
    "\n",
    "# make where work with arbitrary pytrees\n",
    "tree_where = pytc.bcmap(jnp.where)\n",
    "\n",
    "print(tree_where(tree > 2, tree + 100, 0))\n",
    "# Tree(a=0, b=(0.0, 103.0), c=[104. 105. 106.])\n",
    "\n",
    "print(tree.at[tree > 1].apply(lambda x: x + 100))\n",
    "# Tree(a=1, b=(102.0, 103.0), c=[104. 105. 106.])\n",
    "\n",
    "mask = tree_where(tree > 1, True, False)\n",
    "print(tree.at[mask].apply(lambda x: x + 100))\n",
    "# Tree(a=1, b=(102.0, 103.0), c=[104. 105. 106.])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] Use visualization tools with arbitrary pytrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list\n",
      "â”œâ”€â”€ [0]=1\n",
      "â”œâ”€â”€ [1]=[...]\n",
      "â””â”€â”€ [2]=4\n",
      "list\n",
      "â”œâ”€â”€ [0]=1\n",
      "â”œâ”€â”€ [1]:list\n",
      "â”‚   â”œâ”€â”€ [0]=2\n",
      "â”‚   â””â”€â”€ [1]=3\n",
      "â””â”€â”€ [2]=4\n",
      "â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”\n",
      "â”‚Nameâ”‚Typeâ”‚Countâ”‚Sizeâ”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤\n",
      "â”‚[0] â”‚int â”‚1    â”‚    â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤\n",
      "â”‚[1] â”‚listâ”‚2    â”‚    â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤\n",
      "â”‚[2] â”‚int â”‚1    â”‚    â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤\n",
      "â”‚Î£   â”‚listâ”‚4    â”‚    â”‚\n",
      "â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”\n",
      "â”‚Name  â”‚Typeâ”‚Countâ”‚Sizeâ”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤\n",
      "â”‚[0]   â”‚int â”‚1    â”‚    â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤\n",
      "â”‚[1][0]â”‚int â”‚1    â”‚    â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤\n",
      "â”‚[1][1]â”‚int â”‚1    â”‚    â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤\n",
      "â”‚[2]   â”‚int â”‚1    â”‚    â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤\n",
      "â”‚Î£     â”‚listâ”‚4    â”‚    â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import pytreeclass as pytc\n",
    "\n",
    "tree = [1, [2, 3], 4]\n",
    "\n",
    "print(pytc.tree_diagram(tree, depth=1))\n",
    "print(pytc.tree_diagram(tree, depth=2))\n",
    "print(pytc.tree_summary(tree, depth=1))\n",
    "print(pytc.tree_summary(tree, depth=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5] Using `on_setattr` to validate/convert inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type and number range check_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On applying Range(min=1, max=100) for field=`in_dim`:\n",
      "0 not in range [1, 100]\n",
      "On applying IsInstance(klass=<class 'int'>) for field=`in_dim`:\n",
      "1.0 not an instance of <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import pytreeclass as pytc\n",
    "\n",
    "\n",
    "# you can use any function\n",
    "@pytc.autoinit\n",
    "class Range(pytc.TreeClass):\n",
    "    min: int | float = -float(\"inf\")\n",
    "    max: int | float = float(\"inf\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if not (self.min <= x <= self.max):\n",
    "            raise ValueError(f\"{x} not in range [{self.min}, {self.max}]\")\n",
    "        return x\n",
    "\n",
    "\n",
    "@pytc.autoinit\n",
    "class IsInstance(pytc.TreeClass):\n",
    "    klass: type | tuple[type, ...]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if not isinstance(x, self.klass):\n",
    "            raise TypeError(f\"{x} not an instance of {self.klass}\")\n",
    "        return x\n",
    "\n",
    "\n",
    "@pytc.autoinit\n",
    "class Foo(pytc.TreeClass):\n",
    "    # allow in_dim to be an integer between [1,100]\n",
    "    in_dim: int = pytc.field(on_setattr=[IsInstance(int), Range(1, 100)])\n",
    "\n",
    "\n",
    "tree = Foo(1)\n",
    "# no error\n",
    "\n",
    "try:\n",
    "    tree = Foo(0)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    tree = Foo(1.0)\n",
    "except TypeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Array shape and dtype check, then dtype conversion_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On applying ArrayValidator(shape=(3, Ellipsis, 6), dtype=<class 'jax.numpy.float32'>) for field=`array`:\n",
      "Size mismatch, 3 != 1 at dimension 0 \n",
      "\n",
      "On applying ArrayValidator(shape=(3, Ellipsis, 6), dtype=<class 'jax.numpy.float32'>) for field=`array`:\n",
      "Dtype mismatch, array_dtype=dtype('float16') != self.dtype=<class 'jax.numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "import pytreeclass as pytc\n",
    "from typing import Any\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "class ArrayValidator(pytc.TreeClass):\n",
    "    def __init__(self, shape, dtype):\n",
    "        \"\"\"Validate shape and dtype of input array.\n",
    "\n",
    "        Args:\n",
    "            shape: Expected shape of array. available values are int, None, ...\n",
    "                use int for fixed size, None for any size, and ... for any number\n",
    "                of dimensions. for example (..., 1) allows any number of dimensions\n",
    "                with the last dimension being 1. (1, ..., 1) allows any number of\n",
    "                dimensions with the first and last dimensions being 1.\n",
    "            dtype: Expected dtype of array.\n",
    "\n",
    "        Example:\n",
    "            >>> x = jnp.ones((5, 5))\n",
    "            >>> # any number of dimensions with last dim=5\n",
    "            >>> shape = (..., 5)\n",
    "            >>> dtype = jnp.float32\n",
    "            >>> validator = ArrayValidator(shape, dtype)\n",
    "            >>> validator(x)  # no error\n",
    "\n",
    "            >>> # must be 2 dimensions with first dim unconstrained and last dim=5\n",
    "            >>> shape = (None, 5)\n",
    "            >>> validator = ArrayValidator(shape, dtype)\n",
    "            >>> validator(x)  # no error\n",
    "        \"\"\"\n",
    "\n",
    "        if shape.count(...) > 1:\n",
    "            raise ValueError(\"Only one ellipsis allowed\")\n",
    "\n",
    "        for si in shape:\n",
    "            if not isinstance(si, (int, type(...), type(None))):\n",
    "                raise TypeError(f\"Expected int or ..., got {si}\")\n",
    "\n",
    "        self.shape = shape\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if not (hasattr(x, \"shape\") and hasattr(x, \"dtype\")):\n",
    "            raise TypeError(f\"Expected array with shape {self.shape}, got {x}\")\n",
    "\n",
    "        shape = list(self.shape)\n",
    "        array_shape = list(x.shape)\n",
    "        array_dtype = x.dtype\n",
    "\n",
    "        if self.shape and array_dtype != self.dtype:\n",
    "            raise TypeError(f\"Dtype mismatch, {array_dtype=} != {self.dtype=}\")\n",
    "\n",
    "        if ... in shape:\n",
    "            index = shape.index(...)\n",
    "            shape = (\n",
    "                shape[:index]\n",
    "                + [None] * (len(array_shape) - len(shape) + 1)\n",
    "                + shape[index + 1 :]\n",
    "            )\n",
    "\n",
    "        if len(shape) != len(array_shape):\n",
    "            raise ValueError(f\"{len(shape)=} != {len(array_shape)=}\")\n",
    "\n",
    "        for i, (li, ri) in enumerate(zip(shape, array_shape)):\n",
    "            if li is None:\n",
    "                continue\n",
    "            if li != ri:\n",
    "                raise ValueError(f\"Size mismatch, {li} != {ri} at dimension {i}\")\n",
    "        return x\n",
    "\n",
    "\n",
    "# any number of dimensions with firt dim=3 and last dim=6\n",
    "shape = (3, ..., 6)\n",
    "# dtype must be float32\n",
    "dtype = jnp.float32\n",
    "\n",
    "validator = ArrayValidator(shape=shape, dtype=dtype)\n",
    "\n",
    "# convert to half precision from float32\n",
    "converter = lambda x: x.astype(jnp.float16)\n",
    "\n",
    "\n",
    "@pytc.autoinit\n",
    "class Tree(pytc.TreeClass):\n",
    "    array: jax.Array = pytc.field(on_setattr=[validator, converter])\n",
    "\n",
    "\n",
    "x = jnp.ones([3, 1, 2, 6])\n",
    "tree = Tree(array=x)\n",
    "\n",
    "\n",
    "try:\n",
    "    y = jnp.ones([1, 1, 2, 3])\n",
    "    tree = Tree(array=y)\n",
    "except ValueError as e:\n",
    "    print(e, \"\\n\")\n",
    "    # On applying ArrayValidator(shape=(3, Ellipsis, 6), dtype=<class 'jax.numpy.float32'>) for field=`array`:\n",
    "    # Dtype mismatch, array_dtype=dtype('float16') != self.dtype=<class 'jax.numpy.float32'>\n",
    "\n",
    "try:\n",
    "    z = x.astype(jnp.float16)\n",
    "    tree = Tree(array=z)\n",
    "except TypeError as e:\n",
    "    print(e)\n",
    "    # On applying ArrayValidator(shape=(3, Ellipsis, 6), dtype=<class 'jax.numpy.float32'>) for field=`array`:\n",
    "    # Size mismatch, 3 != 1 at dimension 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [6] Freeze custom parameters using `.at` manually/with mask\n",
    "\n",
    "In the following example,  some classes like `Dropout`, can contain some leaves that are differentiable,\n",
    "but we do not wish to update them. in `Dropout` Example, the `drop_rate` is a float that\n",
    "should not be updated by optimization. the following recipe shows how to deal with such values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout(drop_rate=108.0)\n",
      "Dropout(drop_rate=0.0)\n"
     ]
    }
   ],
   "source": [
    "import pytreeclass as pytc\n",
    "import jax\n",
    "\n",
    "\n",
    "@pytc.autoinit\n",
    "class Dropout(pytc.TreeClass):\n",
    "    drop_rate: float = 0.0  # dropout rate, 0 mean no dropout\n",
    "\n",
    "    def __call__(self, x, *, key):\n",
    "        keep_rate = 1.0 - self.drop_rate\n",
    "        mask = jax.random.bernoulli(key, keep_rate, x.shape)\n",
    "        return jnp.where(mask, x / keep_rate, 0.0)\n",
    "\n",
    "\n",
    "x = jnp.arange(10)\n",
    "dropout = Dropout(drop_rate=0.5)\n",
    "dropout(x, key=jax.random.PRNGKey(0))\n",
    "\n",
    "\n",
    "@jax.grad\n",
    "def f(layer: Dropout, x: jax.Array):\n",
    "    return layer(x, key=jax.random.PRNGKey(0)).sum()\n",
    "\n",
    "\n",
    "print(f(dropout, x))\n",
    "# Dropout(drop_rate=108.0)  # <--- this is the gradient which is undesired\n",
    "\n",
    "\n",
    "# lets fix this by freezing the dropout rate\n",
    "@pytc.autoinit\n",
    "class Dropout(pytc.TreeClass):\n",
    "    drop_rate: float = pytc.field(on_setattr=[pytc.freeze], default=0.0)\n",
    "\n",
    "    def __call__(self, x, *, key):\n",
    "        keep_rate = 1.0 - self.drop_rate\n",
    "        mask = jax.random.bernoulli(key, keep_rate, x.shape)\n",
    "        return jnp.where(mask, x / keep_rate, 0.0)\n",
    "\n",
    "\n",
    "x = jnp.arange(10)\n",
    "dropout = Dropout(drop_rate=0.5)\n",
    "\n",
    "dropout\n",
    "# Dropout(drop_rate=#0.5)  # -> dropout rate is frozen, to call dropout layer we need to unfreeze it first\n",
    "\n",
    "\n",
    "@jax.grad\n",
    "def f(layer: Dropout, x: jax.Array):\n",
    "    layer = jax.tree_map(pytc.unfreeze, layer, is_leaf=pytc.is_frozen)\n",
    "    return layer(x, key=jax.random.PRNGKey(0)).sum()\n",
    "\n",
    "\n",
    "f(dropout, x)\n",
    "# Dropout(drop_rate=#0.5)  # <- dropout rate is not updated, can be used safely with optax\n",
    "\n",
    "\n",
    "# lets say, for evaluation we want to set the dropout rate to 0.0\n",
    "# then we can do the following\n",
    "\n",
    "disable_dropout = dropout.at[\"drop_rate\"].set(0.0, is_leaf=pytc.is_frozen)\n",
    "print(disable_dropout)\n",
    "# Dropout(drop_rate=0.0)  # now the dropout rate is 0. and unfrozen.\n",
    "# this layer is now safe to use for evaluation without special handling (like eval in pytorch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [7] Use `PyTreeClass` with `Flax`/`Equinox`\n",
    "The following recipe adds `at` support for `Flax` and `Equinox`. note for equinox use `eqx.Module` instead of `struct.PyTreeNode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlaxTree(a=1, b=(2.0, 3.0), c=f32[3](Î¼=5.00, Ïƒ=0.82, âˆˆ[4.00,6.00]))\n",
      "FlaxTree(a=1, b=(2.0, 3.0), c=[4. 5. 6.])\n",
      "FlaxTree\n",
      "â”œâ”€â”€ .a=1\n",
      "â”œâ”€â”€ .b:tuple\n",
      "â”‚   â”œâ”€â”€ [0]=2.0\n",
      "â”‚   â””â”€â”€ [1]=3.0\n",
      "â””â”€â”€ .c=f32[3](Î¼=5.00, Ïƒ=0.82, âˆˆ[4.00,6.00])\n",
      "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚Name â”‚Type    â”‚Countâ”‚Size  â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚.a   â”‚int     â”‚1    â”‚      â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚.b[0]â”‚float   â”‚1    â”‚      â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚.b[1]â”‚float   â”‚1    â”‚      â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚.c   â”‚f32[3]  â”‚3    â”‚12.00Bâ”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚Î£    â”‚FlaxTreeâ”‚6    â”‚12.00Bâ”‚\n",
      "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FlaxTree(a=10, b=(2.0, 3.0), c=f32[3](Î¼=5.00, Ïƒ=0.82, âˆˆ[4.00,6.00]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "import pytreeclass as pytc\n",
    "from flax import struct\n",
    "\n",
    "import jax\n",
    "import pytreeclass as pytc\n",
    "from flax import struct\n",
    "\n",
    "# note that flax is registered with `jax.tree_util.register_pytree_with_keys`\n",
    "# otherwise for arbitrary objects you need to do the key registration\n",
    "\n",
    "\n",
    "class FlaxTree(struct.PyTreeNode):\n",
    "    a: int = 1\n",
    "    b: tuple[float] = (2.0, 3.0)\n",
    "    c: jax.Array = jax.numpy.array([4.0, 5.0, 6.0])\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return pytc.tree_repr(self)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return pytc.tree_str(self)\n",
    "\n",
    "    @property\n",
    "    def at(self):\n",
    "        return pytc.AtIndexer(self)\n",
    "\n",
    "\n",
    "flax_tree = FlaxTree()\n",
    "\n",
    "print(f\"{flax_tree!r}\")\n",
    "print(f\"{flax_tree!s}\")\n",
    "print(pytc.tree_diagram(flax_tree))\n",
    "print(pytc.tree_summary(flax_tree))\n",
    "\n",
    "flax_tree.at[\"a\"].set(10)\n",
    "# FlaxTree(a=10, b=(2.0, 3.0), c=f32[3](Î¼=5.00, Ïƒ=0.82, âˆˆ[4.00,6.00]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [8] `named_parameters()` like in `PyTreeClass`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NamedSequenceKey(idx=0, name='a'),) 1\n",
      "(NamedSequenceKey(idx=1, name='b'), SequenceKey(idx=0)) 2.0\n",
      "(NamedSequenceKey(idx=1, name='b'), SequenceKey(idx=1)) 3.0\n"
     ]
    }
   ],
   "source": [
    "import pytreeclass as pytc\n",
    "import jax\n",
    "\n",
    "\n",
    "@pytc.autoinit\n",
    "class Tree(pytc.TreeClass):\n",
    "    a: int = 1\n",
    "    b: tuple[float, float] = (2.0, 3.0)\n",
    "\n",
    "\n",
    "tree = Tree()\n",
    "\n",
    "for path, leaf in jax.tree_util.tree_flatten_with_path(tree)[0]:\n",
    "    print(path, leaf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [9] Initialize parameters based on input\n",
    "In this example, a `Linear` layer with a weight parameter based on the shape of the input will be created. Since this requires parameter creation (i.e., `weight`) after instance initialization, we will use `.at` to create a new instance with the added parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer before param is set:\tLazyLinear(out_features=1)\n",
      "Layer after param is set:\tLazyLinear(out_features=1, weight=[[1.]], bias=[0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytreeclass as pytc\n",
    "from typing import Any\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "\n",
    "\n",
    "@pytc.autoinit\n",
    "class LazyLinear(pytc.TreeClass):\n",
    "    out_features: int\n",
    "\n",
    "    def param(self, name: str, value: Any):\n",
    "        # return the value if it exists, otherwise set it and return it\n",
    "        if name not in vars(self):\n",
    "            setattr(self, name, value)\n",
    "        return vars(self)[name]\n",
    "\n",
    "    def __call__(self, x: jax.Array, *, key: jr.KeyArray = jr.PRNGKey(0)):\n",
    "        weight = self.param(\"weight\", jnp.ones((x.shape[-1], self.out_features)))\n",
    "        bias = self.param(\"bias\", jnp.zeros((self.out_features,)))\n",
    "        return x @ weight + bias\n",
    "\n",
    "\n",
    "x = jnp.ones([10, 1])\n",
    "\n",
    "lazy_linear = LazyLinear(out_features=1)\n",
    "\n",
    "lazy_linear\n",
    "print(f\"Layer before param is set:\\t{lazy_linear}\")\n",
    "\n",
    "\n",
    "# first call will set the parameters\n",
    "_, linear = lazy_linear.at[\"__call__\"](x, key=jr.PRNGKey(0))\n",
    "\n",
    "print(f\"Layer after param is set:\\t{linear}\")\n",
    "# subsequent calls will use the same parameters and not set them again\n",
    "linear(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10] Store intermediate values\n",
    "\n",
    "This example shows how to capture specific intermediate values within each function call in this example."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use state threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate values:\t\n",
      " (Array([[0. ],\n",
      "       [0.5],\n",
      "       [1. ],\n",
      "       [1.5],\n",
      "       [2. ]], dtype=float32), Array([[-0.09999937],\n",
      "       [ 0.40000063],\n",
      "       [ 0.90000063],\n",
      "       [ 1.4000006 ],\n",
      "       [ 1.9000006 ]], dtype=float32))\n",
      "\n",
      "Final tree:\t\n",
      " Tree(a=0.801189)\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "import pytreeclass as pytc\n",
    "import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "@pytc.autoinit\n",
    "class Tree(pytc.TreeClass):\n",
    "    a: float = 1.0\n",
    "\n",
    "    def __call__(self, x: jax.Array, intermediate: tuple[Any, ...]):\n",
    "        x = x + self.a\n",
    "        # store intermediate variables\n",
    "        return x, intermediate + (x,)\n",
    "\n",
    "\n",
    "def loss_func(tree: Tree, x: jax.Array, y: jax.Array, intermediate: tuple[Any, ...]):\n",
    "    ypred, intermediate = tree(x, intermediate)\n",
    "    loss = jnp.mean((ypred - y) ** 2)\n",
    "    return loss, intermediate\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(\n",
    "    tree: Tree,\n",
    "    optim_state: optax.OptState,\n",
    "    x: jax.Array,\n",
    "    y: jax.Array,\n",
    "    intermediate: tuple[Any, ...],\n",
    "):\n",
    "    grads, intermediate = jax.grad(loss_func, has_aux=True)(tree, x, y, intermediate)\n",
    "    updates, optim_state = optim.update(grads, optim_state)\n",
    "    tree = optax.apply_updates(tree, updates)\n",
    "    return tree, optim_state, intermediate\n",
    "\n",
    "\n",
    "tree = Tree()\n",
    "optim = optax.adam(1e-1)\n",
    "optim_state = optim.init(tree)\n",
    "\n",
    "x = jnp.linspace(-1, 1, 5)[:, None]\n",
    "y = x**2\n",
    "\n",
    "intermediate = ()\n",
    "\n",
    "for i in range(2):\n",
    "    tree, optim_state, intermediate = train_step(tree, optim_state, x, y, intermediate)\n",
    "\n",
    "\n",
    "print(\"Intermediate values:\\t\\n\", intermediate)\n",
    "print(\"\\nFinal tree:\\t\\n\", tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using [oryx](https://github.com/jax-ml/oryx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate values:\t\n",
      " ({'x': Array([[0. ],\n",
      "       [0.5],\n",
      "       [1. ],\n",
      "       [1.5],\n",
      "       [2. ]], dtype=float32)}, {'x': Array([[-0.09999937],\n",
      "       [ 0.40000063],\n",
      "       [ 0.90000063],\n",
      "       [ 1.4000006 ],\n",
      "       [ 1.9000006 ]], dtype=float32)})\n",
      "\n",
      "Final tree:\t\n",
      " Tree(a=0.801189)\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "import pytreeclass as pytc\n",
    "import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "import oryx\n",
    "\n",
    "\n",
    "@pytc.autoinit\n",
    "class Tree(pytc.TreeClass):\n",
    "    a: float = 1.0\n",
    "\n",
    "    def __call__(self, x: jax.Array):\n",
    "        x = x + self.a\n",
    "        # store intermediate variables with oryx\n",
    "        x = oryx.core.sow(x, tag=\"intermediates\", name=\"x\")\n",
    "        return x\n",
    "\n",
    "\n",
    "def loss_func(tree: Tree, x: jax.Array, y: jax.Array):\n",
    "    ypred = tree(x)\n",
    "    loss = jnp.mean((ypred - y) ** 2)\n",
    "    return loss\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(\n",
    "    tree: Tree,\n",
    "    optim_state: optax.OptState,\n",
    "    x: jax.Array,\n",
    "    y: jax.Array,\n",
    "):\n",
    "    grads = jax.grad(loss_func)(tree, x, y)\n",
    "    updates, optim_state = optim.update(grads, optim_state)\n",
    "    tree = optax.apply_updates(tree, updates)\n",
    "    return tree, optim_state\n",
    "\n",
    "\n",
    "tree = Tree()\n",
    "optim = optax.adam(1e-1)\n",
    "optim_state = optim.init(tree)\n",
    "\n",
    "x = jnp.linspace(-1, 1, 5)[:, None]\n",
    "y = x**2\n",
    "\n",
    "intermediate = ()\n",
    "\n",
    "train_step_reap = oryx.core.reap(train_step, tag=\"intermediates\")\n",
    "\n",
    "for i in range(2):\n",
    "    intermediate += (train_step_reap(tree, optim_state, x, y),)\n",
    "    tree, optim_state = train_step(tree, optim_state, x, y)\n",
    "\n",
    "\n",
    "print(\"Intermediate values:\\t\\n\", intermediate)\n",
    "print(\"\\nFinal tree:\\t\\n\", tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [11] Create layers from configuration files\n",
    "The next example shows how to use `pytreeclass.bcmap` to loop over a configuration dictionary that defines creation of simple linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(\n",
       "   weight=f32[1,1](Î¼=0.31, Ïƒ=0.00, âˆˆ[0.31,0.31]), \n",
       "   bias=f32[1](Î¼=0.00, Ïƒ=0.00, âˆˆ[0.00,0.00])\n",
       " ),\n",
       " Linear(\n",
       "   weight=f32[2,1](Î¼=-1.27, Ïƒ=0.33, âˆˆ[-1.59,-0.94]), \n",
       "   bias=f32[1](Î¼=0.00, Ïƒ=0.00, âˆˆ[0.00,0.00])\n",
       " ),\n",
       " Linear(\n",
       "   weight=f32[3,1](Î¼=0.24, Ïƒ=0.53, âˆˆ[-0.48,0.77]), \n",
       "   bias=f32[1](Î¼=0.00, Ïƒ=0.00, âˆˆ[0.00,0.00])\n",
       " ),\n",
       " Linear(\n",
       "   weight=f32[4,1](Î¼=-0.28, Ïƒ=0.21, âˆˆ[-0.64,-0.08]), \n",
       "   bias=f32[1](Î¼=0.00, Ïƒ=0.00, âˆˆ[0.00,0.00])\n",
       " )]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytreeclass as pytc\n",
    "import jax\n",
    "\n",
    "\n",
    "class Linear(pytc.TreeClass):\n",
    "    def __init__(self, in_dim: int, out_dim: int, *, key: jax.random.KeyArray):\n",
    "        self.weight = jax.random.normal(key, (in_dim, out_dim))\n",
    "        self.bias = jnp.zeros((out_dim,))\n",
    "\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        return x @ self.weight + self.bias\n",
    "\n",
    "\n",
    "config = {\n",
    "    # each layer gets a different input dimension\n",
    "    \"in_dim\": [1, 2, 3, 4],\n",
    "    # out_dim is broadcasted to all layers\n",
    "    \"out_dim\": 1,\n",
    "    # each layer gets a different key\n",
    "    \"key\": list(jax.random.split(jax.random.PRNGKey(0), 4)),\n",
    "}\n",
    "\n",
    "\n",
    "# `bcmap` transforms a function that takes a single input into a function that\n",
    "# arbitrary pytree inputs. in case of a single input, the input is broadcasted\n",
    "# to match the tree structure of the first argument\n",
    "# (in our example is a list of 4 inputs)\n",
    "\n",
    "\n",
    "@pytc.bcmap\n",
    "def build_layer(in_dim, out_dim, *, key: jax.random.KeyArray):\n",
    "    return Linear(in_dim, out_dim, key=key)\n",
    "\n",
    "\n",
    "build_layer(config[\"in_dim\"], config[\"out_dim\"], key=config[\"key\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [12] Model ensembles using `jax.vmap`\n",
    "In this example, simple `Linear` layers are grouped by their weight on the first axis using `jax.vmap`. This is useful if the different instances of the model are desired to run in a vectorized fashion (model ensemble).\n",
    "\n",
    "For more check [here](http://matpalm.com/blog/ensemble_nets/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single input ensemble shape:\t(4, 10, 1)\n",
      "Multi input ensemble shape:\t(4, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import pytreeclass as pytc\n",
    "import functools as ft\n",
    "from typing import Generic, TypeVar\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "\n",
    "class Batched(Generic[T]):\n",
    "    ...\n",
    "\n",
    "\n",
    "class Linear(pytc.TreeClass):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_dim: int,\n",
    "        *,\n",
    "        key: jr.KeyArray,\n",
    "        name: str,\n",
    "    ):\n",
    "        self.weight = jr.normal(key, (in_dim, out_dim))\n",
    "        self.bias = jnp.zeros((out_dim,))\n",
    "        self.name = name  # non-jax type for `tree_mask`/`tree_unmask` demonstration\n",
    "\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        return x @ self.weight + self.bias\n",
    "\n",
    "\n",
    "class FNN(pytc.TreeClass):\n",
    "    def __init__(self, key: jr.KeyArray):\n",
    "        k1, k2, k3 = jr.split(key, 3)\n",
    "        self.l1 = Linear(1, 10, key=k1, name=\"l1\")\n",
    "        self.l2 = Linear(10, 10, key=k2, name=\"l2\")\n",
    "        self.l3 = Linear(10, 1, key=k3, name=\"l3\")\n",
    "\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        x = self.l1(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        x = self.l3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def build_ensemble(keys: jr.KeyArray) -> Batched[FNN]:\n",
    "    @jax.vmap\n",
    "    def build_liner(key: jr.KeyArray):\n",
    "        # `jax.vmap` require jax-type return\n",
    "        # so use `tree_mask` on return\n",
    "        return pytc.tree_mask(FNN(key=key))\n",
    "\n",
    "    return pytc.tree_unmask(build_liner(keys))\n",
    "\n",
    "\n",
    "def run_single_input_ensemble(fnns: Batched[FNN], x: jax.Array):\n",
    "    def run_linear(fnn: FNN):\n",
    "        # `jax.vmap` require jax-type return\n",
    "        # so use `tree_mask` on return\n",
    "        return pytc.tree_mask(fnn(x))\n",
    "\n",
    "    return jax.vmap(run_linear)(pytc.tree_mask(fnns))\n",
    "\n",
    "\n",
    "def run_multi_input_ensemble(fnns: Batched[FNN], x: Batched[jax.Array]):\n",
    "    def run_linear(fnn: FNN, x: jax.Array):\n",
    "        # `jax.vmap` require jax-type return\n",
    "        # so use `tree_mask` on return\n",
    "        return pytc.tree_mask(fnn(x))\n",
    "\n",
    "    return jax.vmap(run_linear)(pytc.tree_mask(fnns), x)\n",
    "\n",
    "\n",
    "num_layers = 4\n",
    "keys = jr.split(jr.PRNGKey(0), num_layers)\n",
    "\n",
    "# single input ensemble\n",
    "# e.g. each model in the ensemble gets the same input\n",
    "x = jnp.ones([10, 1])\n",
    "fnns = build_ensemble(keys=keys)\n",
    "y = run_single_input_ensemble(fnns, x)\n",
    "print(f\"Single input ensemble shape:\\t{y.shape}\")\n",
    "\n",
    "# multi input ensemble\n",
    "# e.g. each model in the ensemble gets a different input\n",
    "xs = jnp.stack([x, x * 2, x * 3, x * 4])\n",
    "fnns = build_ensemble(keys=keys)\n",
    "ys = run_multi_input_ensemble(fnns, xs)\n",
    "print(f\"Multi input ensemble shape:\\t{ys.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [13] Functional method chaining.\n",
    "\n",
    "If a certain class has a method that mutate its internal state, then `.at[method_name].__call__(*args,**kwargs)` is used to return a tuple of method return value and a new instance.\n",
    "This example shows how to leverage `.at` to enable method chaining by using the `at` functionality.\n",
    "\n",
    "The objective is to achieve the following pattern in a functional way.\n",
    "\n",
    "```python\n",
    "instance = instance.method1(...).method2(...).method3(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original instance:\t Tree(a=1)\n",
      "new instance:\t\t Tree(a=5)\n"
     ]
    }
   ],
   "source": [
    "import pytreeclass as pytc\n",
    "\n",
    "\n",
    "@pytc.autoinit\n",
    "class Tree(pytc.TreeClass):\n",
    "    a: int\n",
    "\n",
    "    def _add(self, x):\n",
    "        self.a += x\n",
    "\n",
    "    def add(self, x):\n",
    "        # use `.at` to return the new instance\n",
    "        # and avoid mutating the original instance\n",
    "        _, self = self.at[\"_add\"](x)\n",
    "        # return the new instance and discard the return value\n",
    "        return self\n",
    "\n",
    "    def _mul(self, x):\n",
    "        self.a *= x\n",
    "\n",
    "    def mul(self, x):\n",
    "        # use `.at` to return the new instance\n",
    "        # and avoid mutating the original instance\n",
    "        _, self = self.at[\"_mul\"](x)\n",
    "        # return the new instance and discard the return value\n",
    "        return self\n",
    "\n",
    "\n",
    "tree0 = Tree(a=1)\n",
    "tree1 = tree0.add(1).mul(2).add(1)  # ((1 + 1) * 2) + 1 = 5\n",
    "\n",
    "print(\"original instance:\\t\", tree0)\n",
    "print(\"new instance:\\t\\t\", tree1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [14] Using regular expression masking.\n",
    "In this example, positive values of tree leaves with name starts with `weight_` will be manipulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree(\n",
      "  weight_1=[  1   4   9  16  25  36  49  64  81 100], \n",
      "  weight_2=[ -1  -2  -3  -4  -5  36  49  64  81 100], \n",
      "  bias=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import pytreeclass as pytc\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import re\n",
    "\n",
    "\n",
    "@pytc.autoinit\n",
    "class Tree(pytc.TreeClass):\n",
    "    weight_1: jax.Array = jnp.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "    weight_2: jax.Array = jnp.array([-1, -2, -3, -4, -5, 6, 7, 8, 9, 10])\n",
    "    bias: jax.Array = jnp.ones(10)\n",
    "\n",
    "\n",
    "tree = Tree()\n",
    "\n",
    "positive_mask = jax.tree_map(lambda x: x > 0, tree)  # positive mask\n",
    "tree = tree.at[positive_mask][re.compile(r\"weight_.*\")].apply(lambda x: x**2)\n",
    "print(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
